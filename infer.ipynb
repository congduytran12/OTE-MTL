{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from bucket_iterator import BucketIterator\n",
    "from data_utils import ABSADataReader, build_tokenizer, build_embedding_matrix\n",
    "from models import CMLA, HAST, MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inferer:\n",
    "    \"\"\"A simple inference example\"\"\"\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "       \n",
    "        absa_data_reader = ABSADataReader(data_dir=opt.data_dir)\n",
    "        self.tokenizer = build_tokenizer(data_dir=opt.data_dir)\n",
    "        embedding_matrix = build_embedding_matrix(opt.data_dir, self.tokenizer.word2idx, opt.embed_dim, opt.dataset)\n",
    "        self.idx2tag, self.idx2polarity = absa_data_reader.reverse_tag_map, absa_data_reader.reverse_polarity_map\n",
    "        self.model = opt.model_class(embedding_matrix, opt, self.idx2tag, self.idx2polarity).to(opt.device)\n",
    "        print('loading model {0} ...'.format(opt.model_name))\n",
    "        self.model.load_state_dict(torch.load(opt.state_dict_path, map_location=lambda storage, loc: storage))\n",
    "        # switch model to evaluation mode\n",
    "        self.model.eval()\n",
    "        torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "    def evaluate(self, text):\n",
    "        text_indices = self.tokenizer.text_to_sequence(text)\n",
    "        text_mask = [1] * len(text_indices)\n",
    "        t_sample_batched = {\n",
    "            'text_indices': torch.tensor([text_indices]),\n",
    "            'text_mask': torch.tensor([text_mask], dtype=torch.uint8),\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            t_inputs = [t_sample_batched[col].to(self.opt.device) for col in self.opt.input_cols]\n",
    "            t_ap_spans_pred, t_op_spans_pred, t_triplets_pred = self.model.inference(t_inputs)\n",
    "        \n",
    "        return [t_ap_spans_pred, t_op_spans_pred, t_triplets_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> loading datasets/14lap tokenizer...\n",
      ">>> loading embedding matrix: 300_laptop14_embedding_matrix.pkl\n",
      "loading model mtl ...\n",
      "WiFi connection, pleased, POS\n",
      "WiFi connection, fast, POS\n"
     ]
    }
   ],
   "source": [
    "dataset = 'laptop14'\n",
    "# set your trained models here\n",
    "model_state_dict_paths = {\n",
    "    'mtl': 'state_dict/mtl_'+dataset+'.pkl',\n",
    "}\n",
    "model_classes = {\n",
    "    'mtl': MTL,\n",
    "}\n",
    "input_colses = {\n",
    "    'mtl': ['text_indices', 'text_mask'],\n",
    "}\n",
    "target_colses = {\n",
    "    'mtl': ['ap_indices', 'op_indices', 'triplet_indices', 'text_mask'],\n",
    "}\n",
    "data_dirs = {\n",
    "    'laptop14': 'datasets/14lap',\n",
    "    'rest14': 'datasets/14rest',\n",
    "    'rest15': 'datasets/15rest',\n",
    "    'rest16': 'datasets/16rest',\n",
    "}\n",
    "class Option(object): pass\n",
    "opt = Option()\n",
    "opt.dataset = dataset\n",
    "#opt.model_name = 'mtl'\n",
    "opt.model_name = 'mtl'\n",
    "opt.eval_cols = ['ap_spans', 'op_spans','triplets']\n",
    "opt.model_class = model_classes[opt.model_name]\n",
    "opt.input_cols = input_colses[opt.model_name]\n",
    "opt.target_cols = target_colses[opt.model_name]\n",
    "opt.state_dict_path = model_state_dict_paths[opt.model_name]\n",
    "opt.embed_dim = 300\n",
    "opt.hidden_dim = 300\n",
    "opt.polarities_dim = 4\n",
    "opt.batch_size = 32\n",
    "opt.data_dir = data_dirs[opt.dataset]\n",
    "opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "inf = Inferer(opt)\n",
    "\n",
    "#rest\n",
    "#text = 'Great food but the service was dreadful !'\n",
    "#text = 'the atmosphere is attractive , but a little uncomfortable .'\n",
    "#laptop\n",
    "text = 'I am pleased with the fast log on , speedy WiFi connection and the long battery life ( > 6 hrs ) .'\n",
    "triplets = inf.evaluate(text)[2][0]\n",
    "words = text.split()\n",
    "polarity_map = {0:'N', 1:'NEU', 2:'NEG', 3:'POS'}\n",
    "for triplet in triplets:\n",
    "    ap_beg, ap_end, op_beg, op_end, p = triplet\n",
    "    ap = ' '.join(words[ap_beg:ap_end+1])\n",
    "    op = ' '.join(words[op_beg:op_end+1])\n",
    "    polarity = polarity_map[p]\n",
    "    print(f'{ap}, {op}, {polarity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
